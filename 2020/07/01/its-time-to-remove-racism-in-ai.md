---
layout: post
published: true
title: "It's time to remove racism in A.I."
date: 2020-07-01
author: Larry Velez
categories: AI, technology, racial bias, facial recognition
link: /blog/2020/7/1/its-time-to-remove-racism-in-ai
---

Over six months ago, well before the #BlackLivesMatter protests became widespread, I had written an article that highlighted an algorithm I discovered that clearly demonstrated the racial biases which are being baked into our technology. In that case, it was an algorithm that considered the population of Blacks in a neighborhood to help determine area property values. Now we discover that a data set used for facial recognition nearly put a man in jail erroneously.

Earlier this year, Robert Julian-Borchak Williams was handcuffed and arrested in front of his family for larceny. He was falsely identified by facial recognition technology, a tool regularly used by police.

According to The New York Times, when Williams was being interrogated in jail, investigators showed him a blurry picture of the suspect in question and he replied, "This is not me. You think all Black men look alike?"

Well apparently to facial recognition technology they do, and there is a reason.

"Recent studies by M.I.T. and the National Institute of Standards and Technology, or NIST, have found that while the technology works relatively well on white men, the results are less accurate for other demographics, in part because of a lack of diversity in the images used to develop the underlying databases," explains the NYT.

The facial recognition software used by the Michigan State Police, DataWorks, uses components developed by two companies, NEC and Rank One Computing. "In 2019, algorithms from both companies were included in a federal study of over 100 facial recognition systems that found they were biased, falsely identifying African-American and Asian faces 10 times to 100 times more than Caucasian faces," reports the NYT.

It is doubtful that Williams is the first Black person arrested and falsely accused due to a biased algorithm. As we rightly demand change in our society, A.I. cannot be overlooked because it has the outward appearance of being neutral. Understand that it is not the technology itself, but the data humans input to inform the A.I. results that are the problem. In this case, underrepresentation of Black men in facial recognition technology have biased the results.

The algorithms and data sets that drive technology are developed by humans who carry conscious and unconscious biases. As part of our effort to expunge racism in our society, we must identify and remove the bias data that are shaping dangerous, invisible decisions by A.I.